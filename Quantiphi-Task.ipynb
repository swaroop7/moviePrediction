{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "#import gensim\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "# machine learning\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as st\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, pipeline, metrics, grid_search\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import random\n",
    "\n",
    "random.seed(9001)\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Desktop\\\\interviews\\\\quantiphi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the data from excel to a pandas dataframe \n",
    "xl = pd.ExcelFile(\"Training Sheet.xlsx\")\n",
    "\n",
    "train = xl.parse(xl.sheet_names[0])\n",
    "#print train.head()\n",
    "\n",
    "xl = pd.ExcelFile(\"Scoring Sheet.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create features for the dataset\n",
    "train['same_name_flag'] = train['name'] == train['display_name']\n",
    "\n",
    "train['contains_year2'] = train[\"name\"].apply(lambda x: 1 if '(' in str(x) else 0)\n",
    "\n",
    "\n",
    "train['same_name_flag']  = train['same_name_flag'].astype(int)\n",
    "\n",
    "train['name_length'] = train[\"name\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "train['name_words_len'] = train[\"name\"].apply(lambda x: len(str(x).strip().split()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    intens epic battl sequenc warfar sensual langu...\n",
      "1          sequenc intens action violenc frighten imag\n",
      "2    intens prolong sequenc sci-fi action violenc m...\n",
      "3                                                gener\n",
      "4    intens sequenc action adventur violenc frighte...\n",
      "Name: brr_stemmed_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Create more features for the dataset\n",
    "\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace(',','')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace('.','')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace('/',' ')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace(';','')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace('(','')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace(')','')\n",
    "#train['board_rating_reason'] = train['board_rating_reason'].str.replace('-',' ')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.lower()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['board_rating_reason'] = train['board_rating_reason'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "\n",
    "\n",
    "train['name'] = train['name'].str.replace(',','')\n",
    "train['name'] = train['name'].str.replace('.','')\n",
    "train['name'] = train['name'].str.replace('/',' ')\n",
    "train['name'] = train['name'].str.replace(';','')\n",
    "train['name'] = train['name'].str.replace('(','')\n",
    "train['name'] = train['name'].str.replace(')','')\n",
    "#train['board_rating_reason'] = train['board_rating_reason'].str.replace('-',' ')\n",
    "train['name'] = train['name'].str.lower()\n",
    "\n",
    "train['name_wno_sw'] = train['name'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
    "\n",
    "train['name_wno_sw_length'] = train[\"name_wno_sw\"].apply(lambda x: len(str(x)))\n",
    "train['name_words_wno_sw_len'] = train[\"name_wno_sw\"].apply(lambda x: len(str(x).strip().split()))\n",
    "\n",
    "\n",
    "train['brr_TOKENIZED']=train['board_rating_reason'].apply(lambda x : filter(None,x.split(\" \")))\n",
    "train['brr_stemmed']=train['brr_TOKENIZED'].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "train['brr_stemmed_sentence']=train['brr_stemmed'].apply(lambda x : \" \".join(x))\n",
    "\n",
    "\n",
    "\n",
    "print train['brr_stemmed_sentence'][:5]\n",
    "\n",
    "\n",
    "train = train.drop(['name_wno_sw', 'brr_TOKENIZED', 'brr_stemmed', 'board_rating_reason',], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['first_char'] = train['name'].str.lower().str[0].astype(str)\n",
    "train['last_char'] = train['name'].str.lower().str[-1].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert categorical to numerical and tf-idf for the text columns\n",
    "\n",
    "first_char_dummies_train = pd.get_dummies(train['first_char'], prefix='f_char_')\n",
    "\n",
    "last_char_dummies_train = pd.get_dummies(train['last_char'], prefix='l_char_')\n",
    "\n",
    "genre_dummies_train  = pd.get_dummies(train['genre'])\n",
    "\n",
    "source_dummies_train  = pd.get_dummies(train['source'])\n",
    "\n",
    "mbrdn_dummies_train  = pd.get_dummies(train['movie_board_rating_display_name'])\n",
    "\n",
    "language_dummies_train  = pd.get_dummies(train['language'])\n",
    "\n",
    "pmd_train  = pd.get_dummies(train['production_method'])\n",
    "\n",
    "creative_type_train  = pd.get_dummies(train['creative_type'])\n",
    "\n",
    "mrpdn_train  = pd.get_dummies(train['movie_release_pattern_display_name'])\n",
    "\n",
    "#tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english') # , ngram_range=(1,2)\n",
    "tf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "train_b_rating_reason = tf_vectorizer.fit_transform(train.brr_stemmed_sentence)\n",
    "\n",
    "train_vocab = pd.DataFrame(train_b_rating_reason.todense(), columns=tf_vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "name_tf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1, stop_words = 'english')\n",
    "\n",
    "train_name_data = name_tf_vectorizer.fit_transform(train.name.values.astype('U'))\n",
    "\n",
    "\n",
    "train_name_vocab = pd.DataFrame(train_name_data.todense(), columns=name_tf_vectorizer.get_feature_names())\n",
    "\n",
    "train_name_vocab.columns = ['name_col_f_' + str(col)  for col in train_name_vocab.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the dummies created above\n",
    "\n",
    "train_df = pd.concat([train, train_vocab, train_name_vocab, first_char_dummies_train, last_char_dummies_train, genre_dummies_train, source_dummies_train, mbrdn_dummies_train, language_dummies_train, pmd_train, creative_type_train, mrpdn_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590001583099365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "\n",
    "train_df = train_df.drop(['id', 'name', 'first_char', 'last_char', 'total', 'display_name', 'genre','source','movie_board_rating_display_name', 'language', 'production_method', 'creative_type', 'movie_release_pattern_display_name', 'brr_stemmed_sentence'], axis=1)\n",
    "\n",
    "\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    451\n",
      "2    415\n",
      "6    212\n",
      "8    118\n",
      "Name: Category, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(986, 1256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data to train and test \n",
    "\n",
    "train_df[\"Category\"] = train['Category'].apply(lambda x : x+1 if x%2==1 else x)\n",
    "train_df.loc[train_df['Category'] == 10, 'Category'] = 8\n",
    "print train_df[\"Category\"].value_counts()\n",
    "\n",
    "X_train = train_df.loc[train_df.production_year != 2011]\n",
    "X_test = train_df.loc[train_df.production_year == 2011]\n",
    "Y_train = X_train[\"Category\"]\n",
    "Y_test = X_test[\"Category\"]\n",
    "\n",
    "X_train  = X_train.drop([\"Category\", \"production_year\"],axis=1)\n",
    "X_test  = X_test.drop([\"Category\", \"production_year\"],axis=1)\n",
    "\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('logistic', LogisticRegression(C=1.0, class_weight='balanced', dual=True,\n",
      "          fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=1e-05, verbose=0, warm_start=False))])\n",
      " Test Accuracy: 59.52%\n",
      " Train Accuracy: 63.49%\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic = LogisticRegression(random_state=1)\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_train)\n",
    "\n",
    "n_components = [20, 40, 64, 100]\n",
    "Cs = np.logspace(-4, 4, 3)\n",
    "a = 'ovr'\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "estimator = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_components,\n",
    "                              logistic__C=Cs, \n",
    "                              logistic__random_state=[None],\n",
    "                              logistic__intercept_scaling=[1.0],\n",
    "                              logistic__tol=[0.00001],\n",
    "                              logistic__dual=[True],\n",
    "                              logistic__multi_class=['ovr'],\n",
    "                            logistic__class_weight =['balanced']))\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "best_model = estimator.best_estimator_\n",
    "print best_model    \n",
    "    \n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_model.predict(X_test)) * 100.0))\n",
    "print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_model.predict(X_train)) * 100.0))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471428571429\n"
     ]
    }
   ],
   "source": [
    "#One Vs Rest Classifier\n",
    "\n",
    "OVsR = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, Y_train).predict(X_train)\n",
    "\n",
    "print OVsR.score(X_test, Y_test)\n",
    "\n",
    "#confusion_matrix(Y_train, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True, tol=0.01,\n",
      "  verbose=False)\n",
      " Test Accuracy: 31.90%\n",
      " Train Accuracy: 55.88%\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "svm = SVC(decision_function_shape='ovr', random_state=1)\n",
    "#svm.fit(X_train, Y_train)\n",
    "\n",
    "#print svm.score(X_test, Y_test)\n",
    "\n",
    "#print svm.predict(X_test)\n",
    "\n",
    "param_dist = {\"C\":  [1, 10, 100, 200, 1000, 10000],\n",
    "              #\"gamma\": st.expon(scale=.1),\n",
    "              \"kernel\": ['rbf', 'linear'],\n",
    "              'class_weight':['balanced'],\n",
    "              'tol':[0.01]}\n",
    "\n",
    "random_search = RandomizedSearchCV(svm, param_distributions=param_dist, cv=4, scoring=\"accuracy\", n_jobs=-1)\n",
    "                                   #n_iter=n_iter_search)\n",
    "\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "best_est = random_search.best_estimator_\n",
    "\n",
    "print best_est\n",
    "\n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_est.predict(X_test)) * 100.0))\n",
    "print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_est.predict(X_train)) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=5, max_features=15,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=120,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=True, random_state=9001, verbose=0, warm_start=False)\n",
      " Test Accuracy: 34.76%\n",
      " Train Accuracy: 42.60%\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "random.seed(9001)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_dist = {\"max_depth\": [3, 5, 6, 7, 8, 9],\n",
    "              \"max_features\": [6, 10, 15, 20, 30, None],\n",
    "              \"min_samples_split\": [2, 5, 10, 15, 100,120],\n",
    "              \"min_samples_leaf\": [1, 2, 4, 5, 6, 7],\n",
    "              \"class_weight\": ['balanced'],\n",
    "              \"n_estimators\": [100, 120, 150,250,300],\n",
    "               \"oob_score\": [True],\n",
    "                \"random_state\": [9001]}\n",
    "\n",
    "# run randomized search\n",
    "#n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=8, scoring='accuracy',  n_jobs=-1)\n",
    "                                   #n_iter=n_iter_search)\n",
    "\n",
    "\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "best_est = random_search.best_estimator_\n",
    "print best_est\n",
    "\n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_est.predict(X_test)) * 100.0))\n",
    "print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_est.predict(X_train)) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_sequel\n",
      "name_length\n",
      "name_words_len\n",
      "name_wno_sw_length\n",
      "name_words_wno_sw_len\n",
      "action\n",
      "action brief languag\n",
      "action languag\n",
      "action rude\n",
      "action rude humor\n",
      "action scari imag\n",
      "action sexual\n",
      "action sexual content\n",
      "action violenc\n",
      "action violenc brief\n",
      "action violenc frighten\n",
      "action violenc frighten imag\n",
      "action violenc languag\n",
      "action violenc mild\n",
      "adventur\n",
      "adventur violenc\n",
      "art action\n",
      "battl\n",
      "battl sequenc\n",
      "bloodi\n",
      "bloodi violenc\n",
      "brief\n",
      "brief drug materi\n",
      "brief mild languag\n",
      "brief sensual\n",
      "brief strong\n",
      "brief strong languag\n",
      "brief suggest content\n",
      "content\n",
      "content drug\n",
      "content violenc\n",
      "crude\n",
      "crude humor\n",
      "crude sexual\n",
      "crude sexual content\n",
      "disast\n",
      "disast sequenc\n",
      "disturb\n",
      "disturb imag languag\n",
      "disturb imag themat materi\n",
      "disturb violent\n",
      "drug\n",
      "drug content languag\n",
      "drug materi\n",
      "drug sexual\n",
      "edit\n",
      "exclud\n",
      "fantasi\n",
      "fantasi action\n",
      "fantasi action violenc\n",
      "fi\n",
      "fi action\n",
      "fi action violenc\n",
      "fi action violenc brief\n",
      "fi action violenc languag\n",
      "frighten\n",
      "frighten imag\n",
      "frighten imag brief\n",
      "gener\n",
      "grisli\n",
      "humor\n",
      "humor brief\n",
      "humor languag drug\n",
      "imag\n",
      "imag brief\n",
      "imag languag\n",
      "imag themat\n",
      "imag themat materi\n",
      "imag violenc\n",
      "includ\n",
      "includ nuditi\n",
      "intens\n",
      "intens action\n",
      "intens action violenc\n",
      "intens action violenc frighten\n",
      "intens sci\n",
      "intens sci fi\n",
      "intens sci fi action violenc\n",
      "intens sequenc\n",
      "intens sequenc action\n",
      "intens sequenc sci\n",
      "intens sequenc sci fi\n",
      "intens sequenc sci fi action\n",
      "intens sequenc violenc\n",
      "intens sequenc violenc action\n",
      "intens sequenc violenc action sexual\n",
      "intern\n",
      "intern exclud\n",
      "involv\n",
      "languag\n",
      "languag brief sexual\n",
      "languag crude\n",
      "languag crude sexual\n",
      "languag drug refer\n",
      "languag drug use\n",
      "languag mild\n",
      "languag sexual\n",
      "languag sexual content\n",
      "languag smoke\n",
      "martial\n",
      "martial art\n",
      "martial art action\n",
      "materi brief\n",
      "matur themat materi\n",
      "menac\n",
      "mild\n",
      "mild action\n",
      "mild action rude\n",
      "mild action rude humor\n",
      "mild crude\n",
      "mild rude\n",
      "mild rude humor\n",
      "mild violenc\n",
      "momentari\n",
      "nuditi\n",
      "nuditi drug\n",
      "peril\n",
      "pervas languag\n",
      "pervas languag sexual\n",
      "pervas languag sexual content\n",
      "refer languag\n",
      "rel\n",
      "rude\n",
      "rude humor\n",
      "rude humor mild\n",
      "scari\n",
      "scari imag\n",
      "scene\n",
      "sci\n",
      "sci fi\n",
      "sci fi action\n",
      "sci fi action violenc\n",
      "sci fi action violenc brief\n",
      "sci fi action violenc languag\n",
      "sensual\n",
      "sensual languag\n",
      "sequenc\n",
      "sequenc action\n",
      "sequenc action violenc\n",
      "sequenc fantasi\n",
      "sequenc intens\n",
      "sequenc intens action\n",
      "sequenc intens action violenc\n",
      "sequenc intens action violenc frighten\n",
      "sequenc intens sci\n",
      "sequenc intens sci fi action\n",
      "sequenc languag\n",
      "sequenc martial\n",
      "sequenc martial art\n",
      "sequenc sci\n",
      "sequenc sci fi\n",
      "sequenc sci fi action\n",
      "sequenc sci fi action violenc\n",
      "sequenc violenc\n",
      "sequenc violenc action\n",
      "sequenc violenc action sexual\n",
      "sequenc violenc action sexual content\n",
      "sequenc violenc disturb\n",
      "sequenc violenc disturb imag\n",
      "sex rel\n",
      "sexual\n",
      "sexual content\n",
      "sexual content drug\n",
      "sexual content graphic\n",
      "sexual content includ nuditi\n",
      "sexual content languag\n",
      "sexual content nuditi languag\n",
      "sexual humor languag\n",
      "sexual materi brief\n",
      "sexual refer\n",
      "smoke\n",
      "strong bloodi violenc languag\n",
      "strong bloodi violenc pervas\n",
      "strong graphic violenc languag\n",
      "strong languag\n",
      "strong sexual\n",
      "strong sexual content\n",
      "suggest\n",
      "suggest content\n",
      "suggest materi\n",
      "themat\n",
      "use\n",
      "violenc\n",
      "violenc action\n",
      "violenc action languag\n",
      "violenc action sexual\n",
      "violenc action sexual content\n",
      "violenc brief\n",
      "violenc brief strong languag\n",
      "violenc disturb imag\n",
      "violenc frighten\n",
      "violenc frighten imag\n",
      "violenc gore\n",
      "violenc includ\n",
      "violenc includ intens\n",
      "violenc languag\n",
      "violenc languag brief sexual\n",
      "violenc scari\n",
      "violenc scene sensual\n",
      "violenc sensual\n",
      "violenc tortur\n",
      "warfar\n",
      "name_col_f_2\n",
      "name_col_f_3\n",
      "name_col_f_activity\n",
      "name_col_f_age\n",
      "name_col_f_aliens\n",
      "name_col_f_alvin\n",
      "name_col_f_alvin chipmunks\n",
      "name_col_f_blood\n",
      "name_col_f_book\n",
      "name_col_f_chipmunks\n",
      "name_col_f_christmas\n",
      "name_col_f_chronicles\n",
      "name_col_f_city\n",
      "name_col_f_dark\n",
      "name_col_f_dawn\n",
      "name_col_f_dragon\n",
      "name_col_f_end\n",
      "name_col_f_escape\n",
      "name_col_f_fu\n",
      "name_col_f_harry\n",
      "name_col_f_harry potter\n",
      "name_col_f_hood\n",
      "name_col_f_iron\n",
      "name_col_f_just\n",
      "name_col_f_kingdom\n",
      "name_col_f_kung fu\n",
      "name_col_f_legend\n",
      "name_col_f_man\n",
      "name_col_f_nan\n",
      "name_col_f_new\n",
      "name_col_f_paranormal\n",
      "name_col_f_paranormal activity\n",
      "name_col_f_pirates\n",
      "name_col_f_potter\n",
      "name_col_f_prince\n",
      "name_col_f_sex\n",
      "name_col_f_story\n",
      "name_col_f_transformers\n",
      "f_char__a\n",
      "f_char__c\n",
      "f_char__d\n",
      "f_char__h\n",
      "f_char__i\n",
      "f_char__j\n",
      "f_char__l\n",
      "f_char__n\n",
      "f_char__nan\n",
      "f_char__q\n",
      "f_char__s\n",
      "f_char__t\n",
      "f_char__y\n",
      "l_char__0\n",
      "l_char__3\n",
      "l_char__a\n",
      "l_char__h\n",
      "l_char__nan\n",
      "Action\n",
      "Adventure\n",
      "Comedy\n",
      "Documentary\n",
      "Drama\n",
      "Horror\n",
      "Thriller/Suspense\n",
      "Based on Comic/Graphic Novel\n",
      "Based on Fiction Book/Short Story\n",
      "Based on Musical or Opera\n",
      "Based on Real Life Events\n",
      "Based on TV\n",
      "Based on Theme Park Ride\n",
      "Original Screenplay\n",
      "Spin-Off\n",
      "Not Rated\n",
      "PG\n",
      "PG-13\n",
      "R\n",
      "Animation/Live Action\n",
      "Digital Animation\n",
      "Live Action\n",
      "Multiple Production Methods\n",
      "Contemporary Fiction\n",
      "Dramatization\n",
      "Factual\n",
      "Fantasy\n",
      "Historical Fiction\n",
      "Kids Fiction\n",
      "Science Fiction\n",
      "Super Hero\n",
      "Limited\n",
      "Wide\n"
     ]
    }
   ],
   "source": [
    "importances = best_est.feature_importances_\n",
    "\n",
    "feat_labels = list(X_train.columns.values)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "#for feature in zip(feat_labels, clf.feature_importances_):\n",
    "#    print(feature)\n",
    "    \n",
    "sfm = SelectFromModel(best_est, threshold=0.0005)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, Y_train)\n",
    "\n",
    "cols = []\n",
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.529\n",
      "Best parameters set:\n",
      "\tsvd__n_components: 40\n",
      "\tsvm__C: 1\n",
      "\tsvm__decision_function_shape: 'ovr'\n",
      "\tsvm__tol: 0.0001\n",
      "Pipeline(steps=[('svd', TruncatedSVD(algorithm='randomized', n_components=40, n_iter=5,\n",
      "       random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.0001, verbose=False))])\n",
      " Test Accuracy: 56.67%\n",
      " Train Accuracy: 72.21%\n"
     ]
    }
   ],
   "source": [
    "# Abhishek Thakur\n",
    "# https://www.kaggle.com/abhishek/beating-the-benchmark/code\n",
    "\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "scl = StandardScaler()\n",
    "    \n",
    "svm_model = SVC(random_state=1)\n",
    "    \n",
    "clf = pipeline.Pipeline([('svd', svd), ('scl', scl), ('svm', svm_model)])\n",
    "    \n",
    "    \n",
    "param_grid = {'svd__n_components' : [10, 15, 20, 40], 'svm__C': [1, 9,10, 12, 100], 'svm__tol': [0.0001], \n",
    "                'svm__decision_function_shape': ['ovr']}\n",
    "    \n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring='accuracy', verbose=10, n_jobs=-1, iid=True, refit=True, cv=4)\n",
    "                                     \n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    \n",
    "best_model = model.best_estimator_\n",
    "    \n",
    "print best_model\n",
    "#best_model.fit(Xtrain,Y_train)\n",
    "#preds = best_model.predict(X_test)\n",
    "    \n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_model.predict(X_test)) * 100.0))\n",
    "print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_model.predict(X_train)) * 100.0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1, max_depth=1)\\n\\n# Train the classifier\\nclf.fit(train_df[train_df.columns.difference(['Category'])], train_df['Category'])\\n\\nfeat_labels = list(train_df.columns.values)\\n\\n# Print the name and gini importance of each feature\\n#for feature in zip(feat_labels, clf.feature_importances_):\\n#    print(feature)\\n    \\nsfm = SelectFromModel(clf, threshold=0.005)\\n\\n# Train the selector\\nsfm.fit(X_train, Y_train)\\n\\ncols = []\\n\\nfor feature_list_index in sfm.get_support(indices=True):\\n    print(feat_labels[feature_list_index])\\n    cols.append(feat_labels[feature_list_index])\\n    \\nX_important_train = sfm.transform(X_train)\\n\\nprint X_important_train.shape\\n\\n\\n#if 'production_year' in cols:\\n#    cols.remove('production_year')\\n\\n#X_train = X_train[cols]\\n#X_test = X_test[cols]\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select important features with Random Forest\n",
    "'''\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1, max_depth=1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(train_df[train_df.columns.difference(['Category'])], train_df['Category'])\n",
    "\n",
    "feat_labels = list(train_df.columns.values)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "#for feature in zip(feat_labels, clf.feature_importances_):\n",
    "#    print(feature)\n",
    "    \n",
    "sfm = SelectFromModel(clf, threshold=0.005)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, Y_train)\n",
    "\n",
    "cols = []\n",
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n",
    "    cols.append(feat_labels[feature_list_index])\n",
    "    \n",
    "X_important_train = sfm.transform(X_train)\n",
    "\n",
    "print X_important_train.shape\n",
    "\n",
    "\n",
    "#if 'production_year' in cols:\n",
    "#    cols.remove('production_year')\n",
    "\n",
    "#X_train = X_train[cols]\n",
    "#X_test = X_test[cols]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_est' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c0f471baf20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_est\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m# Transform to df for easier plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m cm_df = pd.DataFrame(cm,\n\u001b[1;32m      5\u001b[0m                      \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'9'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_est' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, best_est.predict(X_test))\n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['1','2','3','4','5','6','7','8','9'], \n",
    "                     columns = ['1','2','3','4','5','6','7','8','9'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\")\n",
    "#plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
