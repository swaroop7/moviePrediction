{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "#import gensim\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "# machine learning\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as st\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, pipeline, metrics, grid_search\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import random\n",
    "from sklearn import cross_validation\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "random.seed(9001)\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Desktop\\\\interviews\\\\quantiphi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'id', u'name', u'display_name', u'production_budget',\n",
      "       u'production_year', u'movie_sequel', u'creative_type', u'source',\n",
      "       u'production_method', u'genre', u'language', u'board_rating_reason',\n",
      "       u'movie_board_rating_display_name',\n",
      "       u'movie_release_pattern_display_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the data from excel to a pandas dataframe \n",
    "\n",
    "xl = pd.ExcelFile(\"Training Sheet.xlsx\")\n",
    "\n",
    "train = xl.parse(xl.sheet_names[0])\n",
    "#print train.head()\n",
    "\n",
    "xl = pd.ExcelFile(\"Scoring Sheet.xlsx\")\n",
    "\n",
    "test = xl.parse(xl.sheet_names[0])\n",
    "#print test.head()\n",
    "\n",
    "print test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create features based on name and display_name\n",
    "\n",
    "train['same_name_flag'] = train['name'] == train['display_name']\n",
    "test['same_name_flag'] = test['name'] == test['display_name']\n",
    "\n",
    "train['contains_year2'] = train[\"name\"].apply(lambda x: 1 if '(' in str(x) else 0)\n",
    "test['contains_year2'] = test[\"name\"].apply(lambda x: 1 if '(' in str(x) else 0)\n",
    "\n",
    "train['same_name_flag']  = train['same_name_flag'].astype(int)\n",
    "test['same_name_flag'] = test[\"same_name_flag\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "train['name_length'] = train[\"name\"].apply(lambda x: len(str(x)))\n",
    "test['name_length'] = test[\"name\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "train['name_words_len'] = train[\"name\"].apply(lambda x: len(str(x).strip().split()))\n",
    "test['name_words_len'] = test[\"name\"].apply(lambda x: len(str(x).strip().split()))\n",
    "\n",
    "#train['display_name_words_len'] = train[\"display_name\"].apply(lambda x: len(str(x).encode('utf-8').strip().split()))\n",
    "#test['display_name_words_len'] = test[\"display_name\"].apply(lambda x: len(str(x).encode('utf-8').strip().split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    intens epic battl sequenc warfar sensual langu...\n",
      "1       sequenc intens action violenc frighten images.\n",
      "2    intens prolong sequenc sci-fi action violenc m...\n",
      "3                                                gener\n",
      "4    intens sequenc action/adventur violenc frighte...\n",
      "Name: brr_stemmed_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create features based on name and display_name\n",
    "\n",
    "#removing special characters from text\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace(',','').replace('.','').replace('/',' ').replace(';','').replace('(','').replace(')','')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.lower()\n",
    "\n",
    "\n",
    "train['board_rating_reason'] = train['board_rating_reason'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "train['name'] = train['name'].str.replace(',','').replace('.','').replace('/',' ').replace(';','').replace('(','').replace(')','')\n",
    "train['name'] = train['name'].str.lower()\n",
    "\n",
    "train['name_wno_sw'] = train['name'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
    "\n",
    "train['name_wno_sw_length'] = train[\"name_wno_sw\"].apply(lambda x: len(str(x)))\n",
    "train['name_words_wno_sw_len'] = train[\"name_wno_sw\"].apply(lambda x: len(str(x).strip().split()))\n",
    "\n",
    "#Porter Stemming \n",
    "train['brr_TOKENIZED']=train['board_rating_reason'].apply(lambda x : filter(None,x.split(\" \")))\n",
    "train['brr_stemmed']=train['brr_TOKENIZED'].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "train['brr_stemmed_sentence']=train['brr_stemmed'].apply(lambda x : \" \".join(x))\n",
    "\n",
    "test['brr_TOKENIZED']=test['board_rating_reason'].apply(lambda x : filter(None,x.split(\" \")))\n",
    "test['brr_stemmed']=test['brr_TOKENIZED'].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "test['brr_stemmed_sentence']=test['brr_stemmed'].apply(lambda x : \" \".join(x))\n",
    "\n",
    "\n",
    "print train['brr_stemmed_sentence'][:5]\n",
    "\n",
    "train = train.drop(['name_wno_sw', 'brr_TOKENIZED', 'brr_stemmed', 'board_rating_reason',], axis=1)\n",
    "test = test.drop(['brr_TOKENIZED', 'brr_stemmed', 'board_rating_reason',], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating features for the first and last character of movie name\n",
    "\n",
    "train['first_char'] = train['name'].str.lower().str[0].astype(str)\n",
    "train['last_char'] = train['name'].str.lower().str[-1].astype(str)\n",
    "\n",
    "test['first_char'] = test['name'].str.lower().str[0].astype(str)\n",
    "test['last_char'] = test['name'].str.lower().str[-1].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating dummy variables for the categorical features and vectorizer on text\n",
    "\n",
    "first_char_dummies_train = pd.get_dummies(train['first_char'], prefix='f_char_')\n",
    "first_char_dummies_test = pd.get_dummies(test['first_char'], prefix='f_char_')\n",
    "\n",
    "last_char_dummies_train = pd.get_dummies(train['last_char'], prefix='l_char_')\n",
    "last_char_dummies_test = pd.get_dummies(test['last_char'], prefix='l_char_')\n",
    "\n",
    "genre_dummies_train  = pd.get_dummies(train['genre'])\n",
    "genre_dummies_test  = pd.get_dummies(test['genre'])\n",
    "\n",
    "source_dummies_train  = pd.get_dummies(train['source'])\n",
    "source_dummies_test  = pd.get_dummies(test['source'])\n",
    "\n",
    "mbrdn_dummies_train  = pd.get_dummies(train['movie_board_rating_display_name'])\n",
    "mbrdn_dummies_test  = pd.get_dummies(test['movie_board_rating_display_name'])\n",
    "\n",
    "language_dummies_train  = pd.get_dummies(train['language'])\n",
    "language_dummies_test  = pd.get_dummies(test['language'])\n",
    "\n",
    "pmd_train  = pd.get_dummies(train['production_method'])\n",
    "pmd_test  = pd.get_dummies(test['production_method'])\n",
    "\n",
    "creative_type_train  = pd.get_dummies(train['creative_type'])\n",
    "creative_type_test  = pd.get_dummies(test['creative_type'])\n",
    "\n",
    "mrpdn_train  = pd.get_dummies(train['movie_release_pattern_display_name'])\n",
    "mrpdn_test  = pd.get_dummies(test['movie_release_pattern_display_name'])\n",
    "\n",
    "#tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english') # , ngram_range=(1,2)\n",
    "tf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "train_b_rating_reason = tf_vectorizer.fit_transform(train.brr_stemmed_sentence)\n",
    "test_b_rating_reason = tf_vectorizer.transform(test.brr_stemmed_sentence)\n",
    "\n",
    "train_vocab = pd.DataFrame(train_b_rating_reason.todense(), columns=tf_vectorizer.get_feature_names())\n",
    "test_vocab = pd.DataFrame(test_b_rating_reason.todense(), columns=tf_vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "name_tf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1, stop_words = 'english')\n",
    "\n",
    "train_name_data = name_tf_vectorizer.fit_transform(train.name.values.astype('U'))\n",
    "test_name_data = name_tf_vectorizer.transform(test.name.values.astype('U'))\n",
    "\n",
    "\n",
    "train_name_vocab = pd.DataFrame(train_name_data.todense(), columns=name_tf_vectorizer.get_feature_names())\n",
    "test_name_vocab = pd.DataFrame(test_name_data.todense(), columns=name_tf_vectorizer.get_feature_names())\n",
    "\n",
    "train_name_vocab.columns = ['name_col_f_' + str(col)  for col in train_name_vocab.columns]\n",
    "test_name_vocab.columns = ['name_col_f_' + str(col)  for col in test_name_vocab.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.concat([train, train_vocab, train_name_vocab, first_char_dummies_train, last_char_dummies_train, genre_dummies_train, source_dummies_train, mbrdn_dummies_train, language_dummies_train, pmd_train, creative_type_train, mrpdn_train], axis=1)\n",
    "\n",
    "test_df = pd.concat([test, test_vocab, first_char_dummies_test, last_char_dummies_test, genre_dummies_test, source_dummies_test, mbrdn_dummies_test, language_dummies_test, pmd_test, creative_type_test, mrpdn_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 1284)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7850000858306885"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "\n",
    "train_df = train_df.drop(['id', 'name', 'first_char', 'last_char', 'total', 'display_name', 'genre','source','movie_board_rating_display_name', 'language', 'production_method', 'creative_type', 'movie_release_pattern_display_name', 'brr_stemmed_sentence'], axis=1)\n",
    "test_df = test_df.drop(['id', 'name', 'first_char', 'last_char', 'production_budget','display_name', 'genre','source','movie_board_rating_display_name', 'language', 'production_method', 'creative_type', 'movie_release_pattern_display_name', 'brr_stemmed_sentence', 'production_year'], axis=1)\n",
    "\n",
    "missing_cols = set( train_df.columns ) - set( test_df.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    test_df[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "score_df = test_df[train_df.columns]\n",
    "\n",
    "score_df  = score_df.drop([\"Category\", \"production_year\"],axis=1)\n",
    "\n",
    "print score_df.shape\n",
    "\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    451\n",
      "2    415\n",
      "6    212\n",
      "8    118\n",
      "Name: Category, dtype: int64\n",
      "(1196, 1286)\n",
      "(986, 1284)\n",
      "(210, 1284)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X = train_df.drop(\"Category\",axis=1)\n",
    "Y = train_df[\"Category\"]\n",
    "X_final  = test_df.drop(\"Category\",axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "'''\n",
    "\n",
    "#Split the data to train and test \n",
    "train_df = shuffle(train_df)\n",
    "\n",
    "\n",
    "train_df[\"Category\"] = train['Category'].apply(lambda x : x+1 if x%2==1 else x)\n",
    "train_df.loc[train_df['Category'] == 10, 'Category'] = 8\n",
    "print train_df[\"Category\"].value_counts()\n",
    "\n",
    "X_train = train_df.loc[train_df.production_year != 2011]\n",
    "X_test = train_df.loc[train_df.production_year == 2011]\n",
    "Y_train = X_train[\"Category\"]\n",
    "Y_test = X_test[\"Category\"]\n",
    "\n",
    "X_train  = X_train.drop([\"Category\", \"production_year\"],axis=1)\n",
    "X_test  = X_test.drop([\"Category\", \"production_year\"],axis=1)\n",
    "\n",
    "print train_df.shape\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "\n",
    "#print np.any(np.isnan(X_test))\n",
    "#print np.all(np.isfinite(X_test))\n",
    "\n",
    "#print pd.isnull(X_test).sum() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to print best scores\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "def report(grid_scores, n_top):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print \"Model with rank: {0}\".format(i + 1)\n",
    "        print \"Mean validation score: {0:.4f})\".format(score.mean_validation_score, np.std(score.cv_validation_scores))\n",
    "        print \"Parameters: {0}\".format(score.parameters)\n",
    "        print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('logistic', LogisticRegression(C=1.0, class_weight='balanced', dual=True,\n",
      "          fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=1e-05, verbose=0, warm_start=False))])\n",
      " Test Accuracy: 58.10%\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.5142)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 64, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': None, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.5132)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 20, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': None, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.5122)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 100, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': None, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.4970)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 40, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': None, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic = LogisticRegression(random_state=1)\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_train)\n",
    "\n",
    "n_components = [20, 40, 64, 100]\n",
    "Cs = np.logspace(-4, 4, 3)\n",
    "a = 'ovr'\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "estimator = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_components,\n",
    "                              logistic__C=Cs, \n",
    "                              logistic__random_state=[None],\n",
    "                              logistic__intercept_scaling=[1.0],\n",
    "                              logistic__tol=[0.00001],\n",
    "                              logistic__dual=[True],\n",
    "                              logistic__multi_class=['ovr'],\n",
    "                            logistic__class_weight =['balanced']))\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "best_model = estimator.best_estimator_\n",
    "print best_model    \n",
    "    \n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_model.predict(X_test)) * 100.0))\n",
    "#print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_model.predict(X_train)) * 100.0))\n",
    "report(estimator.grid_scores_, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.542\n",
      "Best parameters set:\n",
      "\tsvd__n_components: 20\n",
      "\tsvm__C: 1\n",
      "\tsvm__decision_function_shape: 'ovr'\n",
      "Pipeline(steps=[('svd', TruncatedSVD(algorithm='randomized', n_components=20, n_iter=5,\n",
      "       random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      " Test Accuracy: 56.19%\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.5416)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 20}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.5375)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 15}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.5355)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 35}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.5345)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 25}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.5304)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 30}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC with SVD\n",
    "\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "scl = StandardScaler()\n",
    "    \n",
    "svm_model = SVC(random_state=1)\n",
    "    \n",
    "clf = pipeline.Pipeline([('svd', svd), ('scl', scl), ('svm', svm_model)])\n",
    "    \n",
    "    \n",
    "param_grid = {'svd__n_components' : [10, 15, 20, 25, 30, 35, 40, 70], 'svm__C': [0.1, 1, 9,10, 12, 100], \n",
    "                'svm__decision_function_shape': ['ovr']}\n",
    "    \n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring='accuracy', verbose=0, n_jobs=-1, iid=True, refit=True, cv=10)\n",
    "                                     \n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    \n",
    "best_model = model.best_estimator_\n",
    "    \n",
    "print best_model\n",
    "#best_model.fit(Xtrain,Y_train)\n",
    "#preds = best_model.predict(X_test)\n",
    "    \n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_model.predict(X_test)) * 100.0))\n",
    "#print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_model.predict(X_train)) * 100.0))   \n",
    "\n",
    "report(model.grid_scores_, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=3, nthread=-1,\n",
      "       objective='multi:softprob', reg_alpha=0.1, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      " Test Accuracy: 59.52%\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.5325)\n",
      "Parameters: {'n_estimators': 3, 'subsample': 0.9, 'reg_alpha': 0.1, 'colsample_bytree': 0.7, 'max_depth': 9}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.5294)\n",
      "Parameters: {'n_estimators': 3, 'subsample': 0.4, 'reg_alpha': 0.5, 'colsample_bytree': 0.5, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.5223)\n",
      "Parameters: {'n_estimators': 3, 'subsample': 0.6, 'reg_alpha': 0.03, 'colsample_bytree': 0.9, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.5112)\n",
      "Parameters: {'n_estimators': 500, 'subsample': 0.8, 'reg_alpha': 0.1, 'colsample_bytree': 0.5, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.5101)\n",
      "Parameters: {'n_estimators': 100, 'subsample': 0.5, 'reg_alpha': 1.0, 'colsample_bytree': 0.9, 'max_depth': 9}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.5081)\n",
      "Parameters: {'n_estimators': 500, 'subsample': 0.6, 'reg_alpha': 0.03, 'colsample_bytree': 0.9, 'max_depth': 9}\n",
      "\n",
      "Model with rank: 7\n",
      "Mean validation score: 0.5081)\n",
      "Parameters: {'n_estimators': 500, 'subsample': 0.5, 'reg_alpha': 0.1, 'colsample_bytree': 0.5, 'max_depth': 2}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean validation score: 0.5000)\n",
      "Parameters: {'n_estimators': 500, 'subsample': 0.6, 'reg_alpha': 0.1, 'colsample_bytree': 0.9, 'max_depth': 3}\n",
      "\n",
      "Model with rank: 9\n",
      "Mean validation score: 0.4970)\n",
      "Parameters: {'n_estimators': 1000, 'subsample': 0.4, 'reg_alpha': 0.5, 'colsample_bytree': 0.7, 'max_depth': 7}\n",
      "\n",
      "Model with rank: 10\n",
      "Mean validation score: 0.4939)\n",
      "Parameters: {'n_estimators': 1000, 'subsample': 0.9, 'reg_alpha': 0.03, 'colsample_bytree': 1.0, 'max_depth': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Classifier with GridSearch\n",
    "\n",
    "params={\n",
    "    'max_depth': [2,3,5,7,9], #[3,4,5,6,7,8,9], # 5 is good \n",
    "    'subsample': [0.4,0.5,0.6,0.7,0.8,0.9,1.0], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    'colsample_bytree': [0.5,0.6,0.7,0.8,0.9,1.0], #[0.5,0.6,0.7,0.8],\n",
    "    'n_estimators': [3, 40, 100, 500, 1000], #[1000,2000,3000]\n",
    "    #\"n_estimators\": st.randint(3, 40),\n",
    "    'reg_alpha': [0, 0.03, 0.1, 0.5, 1.0] #[0.01, 0.02, 0.03, 0.04]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "rs = RandomizedSearchCV(xgb_clf,\n",
    "                  params,\n",
    "                  cv=6,\n",
    "                  scoring=\"accuracy\",\n",
    "                  n_jobs=-1,\n",
    "                  verbose=1)\n",
    "rs.fit(X_train, Y_train)\n",
    "best_est = rs.best_estimator_\n",
    "print(best_est)\n",
    "\n",
    "\n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_est.predict(X_test)) * 100.0))\n",
    "#print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_est.predict(X_train)) * 100.0))\n",
    "\n",
    "report(rs.grid_scores_, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features=10,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=15,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=True, random_state=9001, verbose=0, warm_start=False)\n",
      " Test Accuracy: 57.62%\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.5416)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 1, 'n_estimators': 300, 'max_features': 10, 'random_state': 9001, 'min_samples_split': 15, 'max_depth': 7, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.5406)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 5, 'n_estimators': 150, 'max_features': 10, 'random_state': 9001, 'min_samples_split': 10, 'max_depth': 6, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.5385)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 4, 'n_estimators': 250, 'max_features': 10, 'random_state': 9001, 'min_samples_split': 100, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.5294)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 4, 'n_estimators': 300, 'max_features': 6, 'random_state': 9001, 'min_samples_split': 10, 'max_depth': 3, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.5284)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 4, 'n_estimators': 150, 'max_features': 20, 'random_state': 9001, 'min_samples_split': 120, 'max_depth': 9, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.5172)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 5, 'n_estimators': 150, 'max_features': 6, 'random_state': 9001, 'min_samples_split': 100, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "random.seed(9001)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_dist = {\"max_depth\": [3, 5, 6, 7, 8, 9],\n",
    "              \"max_features\": [6, 10, 15, 20, 30, None],\n",
    "              \"min_samples_split\": [2, 5, 10, 15, 100,120],\n",
    "              \"min_samples_leaf\": [1, 2, 4, 5, 6, 7],\n",
    "              \"class_weight\": ['balanced'],\n",
    "              \"n_estimators\": [50,100, 120, 150,250,300],\n",
    "               \"oob_score\": [True],\n",
    "                \"random_state\": [9001]}\n",
    "\n",
    "# run randomized search\n",
    "#n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=8, scoring='accuracy',  n_jobs=-1)\n",
    "                                   #n_iter=n_iter_search)\n",
    "\n",
    "\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "best_est = random_search.best_estimator_\n",
    "print best_est\n",
    "\n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_est.predict(X_test)) * 100.0))\n",
    "#print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_est.predict(X_train)) * 100.0))\n",
    "\n",
    "report(random_search.grid_scores_, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_sequel\n",
      "same_name_flag\n",
      "name_length\n",
      "name_words_len\n",
      "name_wno_sw_length\n",
      "name_words_wno_sw_len\n",
      "action\n",
      "action languag\n",
      "action rude humor\n",
      "action sexual content\n",
      "action violenc\n",
      "action violenc brief\n",
      "action violenc frighten\n",
      "action violenc languag\n",
      "action violenc mild\n",
      "action violence\n",
      "adventur\n",
      "adventur action\n",
      "adventur violenc\n",
      "art\n",
      "audienc\n",
      "battl sequenc\n",
      "bloodi\n",
      "bloodi violenc\n",
      "bloodi violenc pervas languag\n",
      "brief\n",
      "brief mild\n",
      "brief sensual\n",
      "brief strong\n",
      "brief strong languag\n",
      "content\n",
      "content languag\n",
      "content languag nuditi\n",
      "content nuditi\n",
      "crude\n",
      "crude humor\n",
      "crude sexual\n",
      "crude sexual content\n",
      "dialogu\n",
      "disast\n",
      "disturb\n",
      "disturb imag\n",
      "disturb violent\n",
      "drug\n",
      "element\n",
      "exclud\n",
      "fantasi\n",
      "fantasi action\n",
      "fi\n",
      "fi action\n",
      "fi action violenc\n",
      "fi action violenc brief\n",
      "frighten\n",
      "frighten imag\n",
      "gener\n",
      "horror\n",
      "humor\n",
      "humor languag drug\n",
      "imag\n",
      "imag brief\n",
      "imag languag\n",
      "imag language\n",
      "includ\n",
      "includ disturb\n",
      "intens\n",
      "intens action\n",
      "intens sequenc\n",
      "intens sequenc action\n",
      "intens sequenc action violenc\n",
      "intens sequenc sci\n",
      "intens sequenc sci fi\n",
      "intens sequenc sci fi action\n",
      "intens sequenc violenc\n",
      "intens sequenc violenc action\n",
      "intens sequenc violenc action sexual\n",
      "intern\n",
      "intern exclud\n",
      "languag\n",
      "languag brief\n",
      "languag sexual\n",
      "languag sexual content\n",
      "languag smoke\n",
      "materi\n",
      "materi includ\n",
      "matur themat\n",
      "mild\n",
      "mild action\n",
      "mild action rude\n",
      "mild action rude humor\n",
      "mild languag\n",
      "mild rude humor\n",
      "nuditi drug\n",
      "nuditi drug use\n",
      "peril\n",
      "pervas\n",
      "pervas languag\n",
      "refer\n",
      "rude\n",
      "rude humor\n",
      "scari\n",
      "scari imag\n",
      "scene sensual\n",
      "sci\n",
      "sci fi\n",
      "sci fi action\n",
      "sci fi action violenc\n",
      "sci fi action violenc brief\n",
      "sensual\n",
      "sequenc\n",
      "sequenc action\n",
      "sequenc action violenc\n",
      "sequenc grisli bloodi\n",
      "sequenc intens\n",
      "sequenc intens action\n",
      "sequenc sci\n",
      "sequenc sci fi\n",
      "sequenc sci fi action\n",
      "sequenc sci fi action violenc\n",
      "sequenc violenc\n",
      "sequenc violenc action\n",
      "sequenc violenc action sexual content\n",
      "sexual\n",
      "sexual content\n",
      "smoke\n",
      "strong\n",
      "strong bloodi\n",
      "strong bloodi violenc\n",
      "strong graphic\n",
      "strong languag\n",
      "strong sexual\n",
      "strong sexual content\n",
      "suggest\n",
      "suggest content\n",
      "terror\n",
      "themat\n",
      "themat element\n",
      "themat materi\n",
      "use\n",
      "violenc\n",
      "violenc action\n",
      "violenc brief\n",
      "violenc brief strong\n",
      "violenc disturb\n",
      "violenc disturb imag\n",
      "violenc frighten\n",
      "violenc frighten imag\n",
      "violenc includ\n",
      "violenc intens\n",
      "violenc languag\n",
      "violenc mild\n",
      "violenc pervas\n",
      "violenc pervas languag\n",
      "violenc sexual\n",
      "violenc terror\n",
      "violence\n",
      "violent disturb\n",
      "warfar\n",
      "name_col_f_2010\n",
      "name_col_f_3\n",
      "name_col_f_alvin\n",
      "name_col_f_alvin chipmunks\n",
      "name_col_f_chronicles\n",
      "name_col_f_dark\n",
      "name_col_f_dawn\n",
      "name_col_f_dragon\n",
      "name_col_f_harry\n",
      "name_col_f_harry potter\n",
      "name_col_f_nan\n",
      "name_col_f_potter\n",
      "name_col_f_prince\n",
      "name_col_f_sex\n",
      "name_col_f_step\n",
      "f_char__d\n",
      "f_char__j\n",
      "f_char__l\n",
      "f_char__t\n",
      "l_char__2\n",
      "l_char__d\n",
      "l_char__s\n",
      "l_char__t\n",
      "Action\n",
      "Adventure\n",
      "Comedy\n",
      "Documentary\n",
      "Drama\n",
      "Horror\n",
      "Romantic Comedy\n",
      "Thriller/Suspense\n",
      "Based on Comic/Graphic Novel\n",
      "Based on Fiction Book/Short Story\n",
      "Based on Real Life Events\n",
      "Based on TV\n",
      "Original Screenplay\n",
      "Remake\n",
      "Not Rated\n",
      "PG\n",
      "PG-13\n",
      "R\n",
      "Animation/Live Action\n",
      "Digital Animation\n",
      "Live Action\n",
      "Contemporary Fiction\n",
      "Dramatization\n",
      "Factual\n",
      "Fantasy\n",
      "Kids Fiction\n",
      "Science Fiction\n",
      "Super Hero\n",
      "Exclusive\n",
      "Limited\n",
      "Wide\n"
     ]
    }
   ],
   "source": [
    "importances = best_est.feature_importances_\n",
    "\n",
    "feat_labels = list(X_train.columns.values)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "#for feature in zip(feat_labels, clf.feature_importances_):\n",
    "#    print(feature)\n",
    "    \n",
    "sfm = SelectFromModel(best_est, threshold=0.001)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, Y_train)\n",
    "\n",
    "cols = []\n",
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 4, 8, 8, 6, 4, 4, 8, 4, 6, 6, 8, 2,\n",
       "       8, 4, 4, 6, 8, 4, 4, 2, 6, 4, 4, 4, 2, 2, 6, 2, 4, 4, 4, 4, 2, 4, 2,\n",
       "       2, 2, 2, 4, 2, 6, 4, 8, 2, 6, 2, 4, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My predictions\n",
    "best_est.predict(score_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAE8CAYAAAC1qXpoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDx9esquNZ1CgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10872d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, best_est.predict(X_test))\n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['2','4','6','8'], \n",
    "                     columns = ['2','4','6','8'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\")\n",
    "#plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
