{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "#import gensim\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "# machine learning\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as st\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, pipeline, metrics, grid_search\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import random\n",
    "from sklearn import cross_validation\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "random.seed(9001)\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Desktop\\\\interviews\\\\quantiphi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the data from excel to a pandas dataframe \n",
    "xl = pd.ExcelFile(\"omdb_v2.xlsx\")\n",
    "\n",
    "omdb = xl.parse(xl.sheet_names[0])\n",
    "#print train.head()\n",
    "\n",
    "train_excel = pd.ExcelFile(\"Training Sheet.xlsx\")\n",
    "scoring_excel = pd.ExcelFile(\"Scoring Sheet.xlsx\")\n",
    "\n",
    "train_data = train_excel.parse(train_excel.sheet_names[0])\n",
    "scoring_data = scoring_excel.parse(scoring_excel.sheet_names[0])\n",
    "\n",
    "train_data = train_data.drop(['genre', 'total'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1287, 38)\n",
      "(1160, 38)\n",
      "(1196, 13)\n",
      "(1096, 49)\n",
      "(1096, 22)\n",
      "Index([                              u'year',\n",
      "                                     u'plot',\n",
      "                                   u'writer',\n",
      "                               u'production',\n",
      "                                   u'actors',\n",
      "                                 u'director',\n",
      "                                 u'released',\n",
      "                                    u'genre',\n",
      "                                  u'runtime',\n",
      "                              u'Unnamed: 37',\n",
      "                                     u'name',\n",
      "                             u'display_name',\n",
      "                          u'production_year',\n",
      "                             u'movie_sequel',\n",
      "                            u'creative_type',\n",
      "                                   u'source',\n",
      "                        u'production_method',\n",
      "                                 u'language',\n",
      "                      u'board_rating_reason',\n",
      "          u'movie_board_rating_display_name',\n",
      "       u'movie_release_pattern_display_name',\n",
      "                                 u'Category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print omdb.shape\n",
    "omdb = omdb[omdb.data_length == 34]\n",
    "print omdb.shape\n",
    "\n",
    "omdb = omdb.drop(['language' ], axis=1)\n",
    "\n",
    "train = pd.merge(omdb, train_data, on='id', how='inner')\n",
    "\n",
    "print train_data.shape\n",
    "\n",
    "print train.shape\n",
    "\n",
    "train = train.drop(['id', 'rated', 'title', 'name_dummy', 'data_length', 'metascore', 'tomato_rating', 'tomato_meter', 'tomato_rotten', 'tomato_consensus', 'tomato_user_meter', 'tomato_fresh', 'imdb_votes', 'type','tomato_user_reviews','website','poster','imdb_id', 'tomato_reviews', 'awards', 'tomato_user_rating', 'dvd','imdb_rating','country','tomato_image', 'box_office', 'response' ], axis=1)\n",
    "\n",
    "print train.shape\n",
    "\n",
    "print train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                        james cameron\n",
      "1                                         ehren kruger\n",
      "2    john lasseter , andrew stanton , lee unkrich ,...\n",
      "3    ted elliott , terry rossio , ted elliott , ter...\n",
      "4                    linda woolverton , lewis carroll \n",
      "5    jonathan nolan , christopher nolan , christoph...\n",
      "6    ted elliott, terry rossio, ted elliott , terry...\n",
      "7                   michael goldenberg , j.k. rowling \n",
      "8                         steve kloves , j.k. rowling \n",
      "9    sam raimi , ivan raimi , alvin sargent , sam r...\n",
      "Name: writer, dtype: object\n",
      "(1096, 2957)\n",
      "(1096, 335)\n",
      "(1096, 2447)\n",
      "(1096, 56)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract features out of actor and writer and director\n",
    "def clean_text(row):\n",
    "    # return the list of decoded cell in the Series instead \n",
    "    return row.decode('unicode_escape').encode('ascii', 'ignore')\n",
    "\n",
    "\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    if isinstance(row['actors'], float) or isinstance(row['actors'], int): \n",
    "        ifor_val = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(row['actors']).encode('utf-8'))\n",
    "    else:\n",
    "        ifor_val =  re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(row['actors'].encode('utf-8')))\n",
    "    train.set_value(index,'actors',ifor_val) \n",
    "        \n",
    "    if isinstance(row['writer'], float) or isinstance(row['writer'], int): \n",
    "        ifor_val = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(row['writer']).encode('utf-8')).lower()\n",
    "    else:\n",
    "        ifor_val =  re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(row['writer'].encode('utf-8'))).lower()\n",
    "    train.set_value(index,'writer',ifor_val) \n",
    "        \n",
    "    ifor_val = str(row['runtime']).replace('min', '').strip()\n",
    "    \n",
    "    train.set_value(index,'runtime',ifor_val)\n",
    "    \n",
    "    if isinstance(row['plot'], float) or isinstance(row['plot'], int): \n",
    "        ifor_val = clean_text(str(row['plot']).encode('utf-8'))\n",
    "    else:\n",
    "        ifor_val =  clean_text(row['plot'].encode('utf-8'))\n",
    "    train.set_value(index,'plot',ifor_val) \n",
    "    \n",
    "\n",
    "print train['writer'].head(10)\n",
    "\n",
    "actor_dummies_train = train['actors'].str.get_dummies(sep=',')\n",
    "\n",
    "print(actor_dummies_train.shape)\n",
    "\n",
    "actor_dummies_train.drop([col for col, val in actor_dummies_train.sum().iteritems() if val < 3], axis=1, inplace=True)\n",
    "\n",
    "print actor_dummies_train.shape\n",
    "\n",
    "\n",
    "writer_dummies_train = train['writer'].str.get_dummies(sep=',')\n",
    "\n",
    "print(writer_dummies_train.shape)\n",
    "\n",
    "writer_dummies_train.drop([col for col, val in writer_dummies_train.sum().iteritems() if val < 3], axis=1, inplace=True)\n",
    "\n",
    "print writer_dummies_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 922)\n",
      "(1096, 52)\n"
     ]
    }
   ],
   "source": [
    "# director\n",
    "director_dummies_train = train['director'].str.get_dummies(sep=',')\n",
    "\n",
    "print(director_dummies_train.shape)\n",
    "\n",
    "director_dummies_train.drop([col for col, val in director_dummies_train.sum().iteritems() if val < 3], axis=1, inplace=True)\n",
    "\n",
    "print director_dummies_train.shape\n",
    "\n",
    "#runtime\n",
    "\n",
    "#train['runtime'] = train['runtime'].str.replace(' min', '').astype(float)\n",
    "\n",
    "#production\n",
    "\n",
    "production_dummies_train =  train['production'].str.get_dummies(sep=',') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#released date, day and weekday etc.   \n",
    "\n",
    "train['release_day'] = pd.DatetimeIndex(train['released']).day\n",
    "train['release_month'] = pd.DatetimeIndex(train['released']).month\n",
    "\n",
    "train['relase_dayofweek'] = pd.DatetimeIndex(train['released']).dayofweek\n",
    "#train['relase_weekofyear'] = pd.weekofyear(train['released']).weekofyear\n",
    "\n",
    "release_day_dummies_train  = pd.get_dummies(train['release_day'], prefix='release_day_')\n",
    "\n",
    "release_month_dummies_train  = pd.get_dummies(train['release_month'], prefix='release_month_')\n",
    "\n",
    "relase_dayofweek_dummies_train  = pd.get_dummies(train['relase_dayofweek'], prefix='release_dayofweek_')\n",
    "\n",
    "train = train.drop(['release_day', 'release_month', 'relase_dayofweek',], axis=1)\n",
    "train = pd.concat([train, release_day_dummies_train, release_month_dummies_train, relase_dayofweek_dummies_train], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create features for the dataset\n",
    "\n",
    "train['same_name_flag'] = train['name'] == train['display_name']\n",
    "\n",
    "train['contains_year2'] = train[\"name\"].apply(lambda x: 1 if '(' in str(x) else 0)\n",
    "\n",
    "\n",
    "train['same_name_flag']  = train['same_name_flag'].astype(int)\n",
    "\n",
    "train['name_length'] = train[\"name\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "train['name_words_len'] = train[\"name\"].apply(lambda x: len(str(x).strip().split()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    intens epic battl sequenc warfar sensual langu...\n",
      "1    intens prolong sequenc sci-fi action violenc m...\n",
      "2                                                gener\n",
      "3    intens sequenc action/adventur violenc frighte...\n",
      "4    fantasi action/viol involv scari imag situat s...\n",
      "Name: brr_stemmed_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Create more features for the dataset\n",
    "\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.replace(',','').replace('.','').replace('/',' ').replace(';','').replace('(','').replace(')','')\n",
    "train['board_rating_reason'] = train['board_rating_reason'].str.lower()\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['board_rating_reason'] = train['board_rating_reason'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "train['name'] = train['name'].str.replace(',','').replace('.','').replace('/',' ').replace(';','').replace('(','').replace(')','')\n",
    "train['name'] = train['name'].str.lower()\n",
    "\n",
    "train['name_wno_sw'] = train['name'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
    "\n",
    "train['name_wno_sw_length'] = train[\"name_wno_sw\"].apply(lambda x: len(str(x)))\n",
    "train['name_words_wno_sw_len'] = train[\"name_wno_sw\"].apply(lambda x: len(str(x).strip().split()))\n",
    "\n",
    "\n",
    "train['brr_TOKENIZED']=train['board_rating_reason'].apply(lambda x : filter(None,x.split(\" \")))\n",
    "train['brr_stemmed']=train['brr_TOKENIZED'].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "train['brr_stemmed_sentence']=train['brr_stemmed'].apply(lambda x : \" \".join(x))\n",
    "\n",
    "\n",
    "print train['brr_stemmed_sentence'][:5]\n",
    "\n",
    "train = train.drop(['name_wno_sw', 'brr_TOKENIZED', 'brr_stemmed', 'board_rating_reason',], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Features for the plot. I am assuming this information would be available before the release of the movie\n",
    "\n",
    "train['plot'] = train['plot'].str.replace(',','').replace('.','').replace('/',' ').replace(';','').replace('(','').replace(')','')\n",
    "train['plot'] = train['plot'].str.lower()\n",
    "\n",
    "train['plot'] = train['plot'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
    "\n",
    "train['plot_TOKENIZED']=train['plot'].apply(lambda x : filter(None,x.split(\" \")))\n",
    "train['plot_stemmed']=train['plot_TOKENIZED'].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "train['plot_stemmed_sentence']=train['plot_stemmed'].apply(lambda x : \" \".join(x))\n",
    "\n",
    "plot_tf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "train_plot_fit = plot_tf_vectorizer.fit_transform(train.plot_stemmed_sentence)\n",
    "\n",
    "train_plot_final = pd.DataFrame(train_plot_fit.todense(), columns=plot_tf_vectorizer.get_feature_names())\n",
    "\n",
    "train_plot_final.columns = ['plot_' + str(col)  for col in train_plot_final.columns]\n",
    "\n",
    "train = train.drop(['plot', 'plot_TOKENIZED', 'plot_stemmed', 'plot_stemmed_sentence',], axis=1)\n",
    "train = pd.concat([train, train_plot_final], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating features for the first and last character of movie name\n",
    "\n",
    "train['first_char'] = train['name'].str.lower().str[0].astype(str)\n",
    "train['last_char'] = train['name'].str.lower().str[-1].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert categorical to numerical and tf-idf for the text columns\n",
    "\n",
    "first_char_dummies_train = pd.get_dummies(train['first_char'], prefix='f_char_')\n",
    "\n",
    "last_char_dummies_train = pd.get_dummies(train['last_char'], prefix='l_char_')\n",
    "\n",
    "genre_dummies_train  = train['genre'].str.get_dummies(sep=',')\n",
    "\n",
    "source_dummies_train  = pd.get_dummies(train['source'])\n",
    "\n",
    "mbrdn_dummies_train  = pd.get_dummies(train['movie_board_rating_display_name'])\n",
    "\n",
    "language_dummies_train  = pd.get_dummies(train['language'])\n",
    "\n",
    "pmd_train  = pd.get_dummies(train['production_method'])\n",
    "\n",
    "creative_type_train  = pd.get_dummies(train['creative_type'])\n",
    "\n",
    "mrpdn_train  = pd.get_dummies(train['movie_release_pattern_display_name'])\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "train_b_rating_reason = tf_vectorizer.fit_transform(train.brr_stemmed_sentence)\n",
    "\n",
    "train_vocab = pd.DataFrame(train_b_rating_reason.todense(), columns=tf_vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "name_tf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1, stop_words = 'english')\n",
    "\n",
    "train_name_data = name_tf_vectorizer.fit_transform(train.name.values.astype('U'))\n",
    "\n",
    "\n",
    "train_name_vocab = pd.DataFrame(train_name_data.todense(), columns=name_tf_vectorizer.get_feature_names())\n",
    "\n",
    "train_name_vocab.columns = ['name_col_f_' + str(col)  for col in train_name_vocab.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the dummies created above\n",
    "\n",
    "train_df = pd.concat([train, train_vocab, production_dummies_train, director_dummies_train, actor_dummies_train, writer_dummies_train, train_name_vocab, mbrdn_dummies_train, first_char_dummies_train, last_char_dummies_train, genre_dummies_train, source_dummies_train, language_dummies_train, pmd_train, creative_type_train, mrpdn_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.47499990463257"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "\n",
    "train_df = train_df.drop([ 'name', 'runtime', 'released', 'Unnamed: 37', 'actors', 'director', 'writer', 'first_char', 'last_char', 'display_name', 'movie_board_rating_display_name', 'genre','source', 'language', 'production', 'production_method', 'creative_type', 'movie_release_pattern_display_name', 'brr_stemmed_sentence'], axis=1)\n",
    "\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    427\n",
      "2    364\n",
      "6    198\n",
      "8    107\n",
      "Name: Category, dtype: int64\n",
      "(1096, 6232)\n",
      "(903, 6230)\n",
      "(193, 6230)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas\\indexes\\base.py:2134: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  return self._engine.get_loc(key)\n"
     ]
    }
   ],
   "source": [
    "#Split the data to train and test \n",
    "train_df = shuffle(train_df)\n",
    "\n",
    "\n",
    "train_df[\"Category\"] = train['Category'].apply(lambda x : x+1 if x%2==1 else x)\n",
    "train_df.loc[train_df['Category'] == 10, 'Category'] = 8\n",
    "print train_df[\"Category\"].value_counts()\n",
    "\n",
    "X_train = train_df.loc[train_df.production_year != 2011]\n",
    "X_test = train_df.loc[train_df.production_year == 2011]\n",
    "Y_train = X_train[\"Category\"]\n",
    "Y_test = X_test[\"Category\"]\n",
    "\n",
    "X_train  = X_train.drop([\"Category\", \"production_year\"],axis=1)\n",
    "X_test  = X_test.drop([\"Category\", \"production_year\"],axis=1)\n",
    "\n",
    "print train_df.shape\n",
    "print X_train.shape\n",
    "print X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to print best scores\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "def report(grid_scores, n_top):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.4f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=250, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('logistic', LogisticRegression(C=1.0, class_weight='balanced', dual=True,\n",
      "          fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=999,\n",
      "          solver='liblinear', tol=1e-05, verbose=0, warm_start=False))])\n",
      " Test Accuracy: 53.89%\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.5515)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 250, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': 999, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.5504)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 1000, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': 999, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.5504)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 2000, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': 999, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.5482)\n",
      "Parameters: {'logistic__tol': 1e-05, 'pca__n_components': 400, 'logistic__dual': True, 'logistic__class_weight': 'balanced', 'logistic__C': 1.0, 'logistic__random_state': 999, 'logistic__intercept_scaling': 1.0, 'logistic__multi_class': 'ovr'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic = LogisticRegression(random_state=1)\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_train)\n",
    "\n",
    "n_components = [20, 40, 64, 100, 150, 200, 250, 300, 400, 500, 1000,2000]\n",
    "Cs = np.logspace(-4, 4, 3)\n",
    "a = 'ovr'\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "estimator = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_components,\n",
    "                              logistic__C=Cs, \n",
    "                              logistic__random_state=[999],\n",
    "                              logistic__intercept_scaling=[1.0],\n",
    "                              logistic__tol=[0.00001],\n",
    "                              logistic__dual=[True],\n",
    "                              logistic__multi_class=['ovr'],\n",
    "                            logistic__class_weight =['balanced']))\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "best_model = estimator.best_estimator_\n",
    "print best_model    \n",
    "    \n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_model.predict(X_test)) * 100.0))\n",
    "#print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_model.predict(X_train)) * 100.0))    \n",
    "\n",
    "report(estimator.grid_scores_, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.565\n",
      "Best parameters set:\n",
      "\tsvd__n_components: 30\n",
      "\tsvm__C: 1\n",
      "\tsvm__decision_function_shape: 'ovr'\n",
      " Test Accuracy: 58.55%\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.5648)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 30}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.5648)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 60}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.5615)\n",
      "Parameters: {'svm__C': 12, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 70}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.5604)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 40}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.5592)\n",
      "Parameters: {'svm__C': 1, 'svm__decision_function_shape': 'ovr', 'svd__n_components': 35}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC with SVD\n",
    "\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "scl = StandardScaler()\n",
    "    \n",
    "svm_model = SVC(random_state=1)\n",
    "    \n",
    "clf = pipeline.Pipeline([('svd', svd), ('scl', scl), ('svm', svm_model)])\n",
    "    \n",
    "    \n",
    "param_grid = {'svd__n_components' : [10, 15, 20, 25, 30, 35, 40, 60,70, 100], 'svm__C': [0.1, 1, 9, 10, 12, 100],  \n",
    "                'svm__decision_function_shape': ['ovr']}\n",
    "    \n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring='accuracy', verbose=1, n_jobs=-1, iid=True, refit=True, cv=10)\n",
    "                                     \n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "#print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_model.predict(X_test)) * 100.0))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    \n",
    "best_model = model.best_estimator_\n",
    "    \n",
    "#print best_model\n",
    "#best_model.fit(Xtrain,Y_train)\n",
    "#preds = best_model.predict(X_test)\n",
    "    \n",
    "#print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_model.predict(X_train)) * 100.0))    \n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_model.predict(X_test)) * 100.0))\n",
    "report(model.grid_scores_, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=12, max_features=10,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1500, n_jobs=1,\n",
      "            oob_score=True, random_state=9001, verbose=0, warm_start=False)\n",
      " Test Accuracy: 55.96%\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.5659)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 1, 'n_estimators': 1500, 'max_features': 10, 'random_state': 9001, 'min_samples_split': 10, 'max_depth': 12, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.5437)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 2, 'n_estimators': 200, 'max_features': 20, 'random_state': 9001, 'min_samples_split': 10, 'max_depth': 9, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.5360)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 1, 'n_estimators': 200, 'max_features': 20, 'random_state': 9001, 'min_samples_split': 2, 'max_depth': 20, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.5360)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 10, 'n_estimators': 300, 'max_features': 100, 'random_state': 9001, 'min_samples_split': 20, 'max_depth': 12, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.5338)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 1, 'n_estimators': 150, 'max_features': None, 'random_state': 9001, 'min_samples_split': 20, 'max_depth': 9, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.5338)\n",
      "Parameters: {'oob_score': True, 'min_samples_leaf': 5, 'n_estimators': 500, 'max_features': 75, 'random_state': 9001, 'min_samples_split': 10, 'max_depth': 3, 'class_weight': 'balanced'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "random.seed(9001)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\"max_depth\": [3, 6, 9,12,20],\n",
    "              \"max_features\": [6, 10, 15, 20, 30, 40, 60, 75, 100, None],\n",
    "              \"min_samples_split\": [2, 5, 10, 15,20,50,100],\n",
    "              \"min_samples_leaf\": [ 1, 2, 5, 10],\n",
    "              \"class_weight\": ['balanced'],\n",
    "              \"n_estimators\": [100, 150, 200, 300,500,1000,1500,2000],\n",
    "               \"oob_score\": [True],\n",
    "                \"random_state\": [9001]}\n",
    "\n",
    "# run randomized search\n",
    "#n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=10, scoring='accuracy',  n_jobs=-1, verbose=1)\n",
    "                                   #n_iter=n_iter_search)\n",
    "\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "best_est = random_search.best_estimator_\n",
    "print best_est\n",
    "\n",
    "print(\" Test Accuracy: %.2f%%\" % (accuracy_score(Y_test, best_est.predict(X_test)) * 100.0))\n",
    "#print(\" Train Accuracy: %.2f%%\" % (accuracy_score(Y_train, best_est.predict(X_train)) * 100.0))\n",
    "report(random_search.grid_scores_, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "movie_sequel\n",
      "release_month__1.0\n",
      "release_month__5.0\n",
      "release_month__6.0\n",
      "release_month__9.0\n",
      "release_month__10.0\n",
      "release_month__12.0\n",
      "name_length\n",
      "name_words_len\n",
      "name_wno_sw_length\n",
      "name_words_wno_sw_len\n",
      "plot_agent\n",
      "plot_alien\n",
      "plot_assassin\n",
      "plot_begin\n",
      "plot_black\n",
      "plot_centuri\n",
      "plot_confront\n",
      "plot_crew\n",
      "plot_danger\n",
      "plot_decid\n",
      "plot_defeat\n",
      "plot_enemi\n",
      "plot_evil\n",
      "plot_famili\n",
      "plot_final\n",
      "plot_friend\n",
      "plot_future\n",
      "plot_grown\n",
      "plot_iron\n",
      "plot_king\n",
      "plot_love\n",
      "plot_new\n",
      "plot_pass\n",
      "plot_piec\n",
      "plot_plan\n",
      "plot_prevent\n",
      "plot_princ\n",
      "plot_promis\n",
      "plot_return\n",
      "plot_revenge\n",
      "plot_round\n",
      "plot_save\n",
      "plot_stand\n",
      "plot_stori\n",
      "plot_surround\n",
      "plot_travel\n",
      "plot_treacher\n",
      "plot_villain\n",
      "plot_want\n",
      "plot_world\n",
      "plot_year\n",
      "plot_year pass\n",
      "plot_young\n",
      "action\n",
      "action violenc\n",
      "content\n",
      "drug\n",
      "drug use\n",
      "exclud\n",
      "fantasi\n",
      "fi\n",
      "fi action\n",
      "fi action violenc\n",
      "frighten\n",
      "humor\n",
      "imag\n",
      "includ disturb\n",
      "intens\n",
      "intens sequenc\n",
      "intens sequenc action\n",
      "intens sequenc sci fi action\n",
      "intens sequenc violenc action\n",
      "intern\n",
      "intern exclud\n",
      "languag\n",
      "languag sexual\n",
      "languag sexual content\n",
      "mild\n",
      "mild action\n",
      "rude humor\n",
      "sci\n",
      "sci fi\n",
      "sci fi action\n",
      "sci fi action violenc\n",
      "sequenc\n",
      "sequenc action\n",
      "sequenc sci\n",
      "sequenc sci fi action\n",
      "sequenc sci fi action violenc\n",
      "sequenc violenc\n",
      "sequenc violenc action\n",
      "sexual\n",
      "strong sexual content\n",
      "themat\n",
      "use\n",
      "violenc\n",
      "violenc action\n",
      "Sony Pictures\n",
      "Sony Pictures Classics\n",
      "Walt Disney Pictures\n",
      " Angelina Jolie\n",
      " Will Arnett\n",
      "Not Rated\n",
      "PG\n",
      "PG-13\n",
      "R\n",
      " Action\n",
      " Adventure\n",
      " Drama\n",
      " Family\n",
      " Fantasy\n",
      " Sci-Fi\n",
      "Action\n",
      "Animation\n",
      "Comedy\n",
      "Documentary\n",
      "Drama\n",
      "Horror\n",
      "Based on Real Life Events\n",
      "Based on TV\n",
      "Original Screenplay\n",
      "Animation/Live Action\n",
      "Digital Animation\n",
      "Live Action\n",
      "Contemporary Fiction\n",
      "Factual\n",
      "Fantasy\n",
      "Kids Fiction\n",
      "Limited\n",
      "Wide\n"
     ]
    }
   ],
   "source": [
    "importances = best_est.feature_importances_\n",
    "\n",
    "feat_labels = list(X_train.columns.values)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "#for feature in zip(feat_labels, clf.feature_importances_):\n",
    "#    print(feature)\n",
    "    \n",
    "sfm = SelectFromModel(best_est, threshold=0.001)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, Y_train)\n",
    "\n",
    "cols = []\n",
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAE8CAYAAAC1qXpoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e22cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, best_model.predict(X_test))\n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['2','4','6','8'], \n",
    "                     columns = ['2','4','6','8'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\")\n",
    "#plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntime1 = time.time()\\n\\nfrom sklearn.utils import class_weight\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Activation\\nfrom keras.optimizers import SGD\\n\\nclass_weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\\n\\n\\nmodel = Sequential()\\nmodel.add(Dense(5000, activation='relu', input_dim=X_train.shape[1]))\\nmodel.add(Dropout(0.1))\\nmodel.add(Dense(600, activation='relu'))\\nmodel.add(Dropout(0.1))\\nmodel.add(Dense(y_train.shape[1], activation='sigmoid'))\\n\\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\\nmodel.compile(loss='binary_crossentropy',\\n              optimizer=sgd, \\n              metrics=['accuracy'])\\n\\nmodel.fit(X_train, Y_train, epochs=10, batch_size=100, class_weight=class_weight, use_multiprocessing=True)\\n\\npreds = model.predict(X_test)\\npreds[preds>=0.5] = 1\\npreds[preds<0.5] = 0\\n\\nprint time1-time.time()\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "time1 = time.time()\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5000, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=100, class_weight=class_weight, use_multiprocessing=True)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "\n",
    "print time1-time.time()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
